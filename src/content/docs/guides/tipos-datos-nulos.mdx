---
title: Tipos de datos y manejo de valores nulos
description: CÃ³mo trabajar con tipos de datos y valores nulos en PySpark.
---

Trabajar correctamente con **tipos de datos** y **valores nulos** es fundamental en PySpark, ya que errores de tipo o datos faltantes pueden generar fallas silenciosas o errores al ejecutar transformaciones.

### ğŸ”¹ Tipos de datos en PySpark (`DataTypes`)

PySpark tiene tipos de datos similares a SQL y pandas, pero definidos en `pyspark.sql.types`.

#### ğŸ“¦ Tipos mÃ¡s comunes:

| Tipo PySpark | DescripciÃ³n |
|---|---|
| `StringType()` | Texto (cadenas de caracteres) |
| `IntegerType()` | Enteros |
| `FloatType()` | Decimales de precisiÃ³n simple |
| `DoubleType()` | Decimales de doble precisiÃ³n |
| `BooleanType()` | Verdadero/Falso |
| `DateType()` | Fecha sin hora |
| `TimestampType()` | Fecha y hora |

#### ğŸ“Œ Ejemplo de esquema manual:

```python
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

schema = StructType([
    StructField("nombre", StringType(), True),
    StructField("edad", IntegerType(), True)
])
```

### ğŸ”¹ ConversiÃ³n de tipos (`cast`)

Puedes cambiar el tipo de una columna con `cast()`:

```python
from pyspark.sql.functions import col

df.withColumn("edad", col("edad").cast("double"))
```

âœ… Ãštil cuando Spark infiere mal los tipos o al leer datos desde CSV.

### ğŸ”¹ VerificaciÃ³n de tipos

```python
df.dtypes         # Lista de columnas y sus tipos
df.printSchema()  # VisualizaciÃ³n del esquema jerÃ¡rquico
```

#### âš ï¸ Errores comunes por tipos de datos

* Comparar `StringType` con `IntegerType`
* Multiplicar columnas de tipo `null`
* Usar funciones matemÃ¡ticas con valores no numÃ©ricos

### ğŸš¨ Manejo de valores nulos

Los valores nulos (`null`) son muy comunes en datasets reales. PySpark ofrece varias funciones para trabajar con ellos de forma segura.

### ğŸ”¹ Detectar nulos: `isNull()` y `isNotNull()`

```python
df.filter(col("email").isNull())
df.filter(col("edad").isNotNull())
```

### ğŸ”¹ Eliminar filas nulas: `dropna()`

```python
df.dropna()                      # Elimina filas con cualquier nulo
df.dropna(subset=["nombre"])     # Solo si 'nombre' es nulo
```

### ğŸ”¹ Rellenar nulos: `fillna()`

```python
df.fillna({"ciudad": "Desconocido", "edad": 0})
```

TambiÃ©n funciona para una sola columna:

```python
df.fillna("SinNombre", subset=["nombre"])
```

### ğŸ”¹ Reemplazar valores: `na.replace()`

```python
df.na.replace("NA", None)
df.na.replace(["", "n/a"], "Desconocido", subset=["ciudad"])
```

### ğŸ”¹ Valores nulos en agregaciones

Algunas funciones ignoran automÃ¡ticamente los nulos (`avg`, `sum`), pero otras podrÃ­an verse afectadas. Es buena prÃ¡ctica limpiar o imputar antes de agregaciones.

### ğŸ§  Buenas prÃ¡cticas

* **Revisa siempre los nulos** antes de transformaciones (`filter`, `groupBy`, `join`).
* **Evita errores de tipo** usando `cast` cuando leas desde CSV o JSON.
* **Define esquemas explÃ­citos** en lectura de datos complejos.
* Usa `.fillna()` en columnas clave como IDs, nombres o edades.

### ğŸ§ª Ejemplo completo de limpieza

```python
df_limpio = df.dropna(subset=["nombre"]) \
              .fillna({"ciudad": "Desconocido", "edad": 0}) \
              .withColumn("edad", col("edad").cast("integer"))
```