---
title: Persistencia y optimizaci贸n
description: T茅cnicas para mejorar el rendimiento en PySpark.
---

La persistencia y la optimizaci贸n son esenciales en PySpark para mejorar el rendimiento, reducir tiempos de ejecuci贸n y evitar operaciones costosas repetidas durante el procesamiento distribuido.

###  Persistencia: Cache vs Persist

PySpark ejecuta operaciones de forma **perezosa** (lazy), lo que significa que no se ejecutan hasta que se necesita un resultado. Al persistir un DataFrame o RDD, evitamos recalcularlo en cada acci贸n.

#### `cache()`

* Almacena el DataFrame/RDD en memoria.
* til cuando se reutiliza varias veces y entra en memoria.

```python
df.cache()
df.count()  # Fuerza la ejecuci贸n
```

#### `persist()`

* M谩s flexible que `cache()`, permite elegir el nivel de almacenamiento.

```python
from pyspark.storagelevel import StorageLevel

df.persist(StorageLevel.MEMORY_AND_DISK)
df.count()
```

**Niveles comunes:**

| Nivel | Descripci贸n |
|---|---|
| MEMORY_ONLY | Solo en memoria (error si no cabe) |
| MEMORY_AND_DISK | Memoria y disco si es necesario |
| DISK_ONLY | Solo en disco |
| MEMORY_ONLY_SER | Memoria con serializaci贸n |

#### `unpersist()`

* Libera el espacio ocupado por el DataFrame/RDD:

```python
df.unpersist()
```

### 锔 Optimizaci贸n de ejecuciones

#### 1. **Proyecci贸n selectiva (column pruning)**

Evita cargar columnas innecesarias:

```python
df.select("nombre", "edad")
```

#### 2. **Filtro temprano (predicate pushdown)**

Aplica filtros lo antes posible para reducir datos:

```python
df.filter("edad > 30")
```

#### 3. **Uso de formatos eficientes**

Parquet y ORC son preferibles a CSV o JSON.

```python
df.write.parquet("ruta/")
```

#### 4. **Uso de `explain()` para analizar planes**

Permite revisar el plan de ejecuci贸n y detectar cuellos de botella:

```python
df.explain(True)
```

###  Broadcast joins

Cuando uno de los DataFrames es peque帽o, es mejor transmitirlo (broadcast):

```python
from pyspark.sql.functions import broadcast

df1.join(broadcast(df2), "id")
```

Esto evita el shuffle de datos masivo.

###  Buenas pr谩cticas de optimizaci贸n

* Lee solo lo necesario: columnas y filas.
* Usa `cache()` cuando el DF ser谩 reutilizado.
* Prefiere `parquet` u `ORC` por su compresi贸n y estructura.
* Combina `repartition()` antes de `write()` para evitar miles de archivos peque帽os.
* Observa el n煤mero de particiones y ajusta seg煤n el tama帽o del cluster.